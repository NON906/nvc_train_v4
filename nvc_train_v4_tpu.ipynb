{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nvc_train_v4_tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_KoOiEAlCei"
      },
      "source": [
        "- 全ての手順については[こちら](nvc_train_v4.ipynb)\n",
        "- 上から順に実行してください\n",
        "- ファイルのアップロードは左メニューのフォルダのアイコンから行えます"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMvhduaanwx9"
      },
      "source": [
        "## 3. 音源の学習処理\n",
        "\n",
        "- この処理はTPU専用です。上部メニューの「ランタイム→ランタイムのタイプを変更」からTPUを使用するように設定してください\n",
        "- この処理は自動では終了しません。また、再度実行すると途中から再開することができます。「4.」で確認して適宜実行や中断を行ってください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_gmsB6EoEx0"
      },
      "source": [
        "# Googleドライブに接続\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcinO5-NuoOS"
      },
      "source": [
        "#!git clone --depth 1 \"https://github.com/NON906/nvc_train_v4.git\"\n",
        "!git clone --depth 1 \"https://NON906:****@gitlab.com/NON906/nvc_train_v4.git\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAiPSbMfm_eU"
      },
      "source": [
        "# ---\n",
        "# 設定パラメータ（※実行前に設定してください）\n",
        "\n",
        "# 入力の解析済みファイル\n",
        "targets_zip_file = 'drive/My Drive/targets_UnityChan.zip' # 'drive/My Drive/targets.zip'\n",
        "\n",
        "# ---\n",
        "\n",
        "!unzip \"{targets_zip_file}\" -d targets > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq0whWEXuMpP"
      },
      "source": [
        "# ---\n",
        "# 設定パラメータ（※実行前に設定してください）\n",
        "\n",
        "# 出力ディレクトリ\n",
        "model_dir_path = 'drive/My Drive/nvc'\n",
        "\n",
        "# ---\n",
        "\n",
        "try:\n",
        "    start_file_epoch = int(open(model_dir_path + '/epoch.txt', 'r').read())\n",
        "    start_file_dir = model_dir_path\n",
        "except FileNotFoundError:\n",
        "    start_file_epoch = 0\n",
        "    start_file_dir = None\n",
        "load_optim_weights = True\n",
        "phoneme_model_path = 'nvc_train_v4/phoneme.h5'\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, LSTM, Reshape, Lambda, Layer, Input, Concatenate\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.constraints import unit_norm\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from tensorflow.keras.losses import Loss, MeanSquaredError, CategoricalCrossentropy\n",
        "import glob\n",
        "import struct\n",
        "import numpy as np\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "\n",
        "\n",
        "class VoiceGenerator():\n",
        "    def __init__(self, dir_path, val_file, batch_size, length=None, train=True, start_cut=0, max_size=None, gender=None):\n",
        "        self.length = length\n",
        "        self.batch_size = batch_size\n",
        "        self.train = train\n",
        "        self.val_file = val_file\n",
        "        \n",
        "        self.index = 0\n",
        "        self.gender = gender\n",
        "        self.get_input_files(dir_path)\n",
        "        \n",
        "        self.max_size = max_size\n",
        "        \n",
        "        self.cut = start_cut\n",
        "\n",
        "        ORDER = 32\n",
        "        ORDER_OUTPUT = 128\n",
        "        CONCAT_MUL = 1\n",
        "        self.silent_array = []\n",
        "        file_data = open('nvc_train_v4/silent.mc', 'rb').read()\n",
        "        for loop in range(len(file_data) // (4 * (ORDER + 1) * CONCAT_MUL)):\n",
        "            for loop2 in range(CONCAT_MUL):\n",
        "                self.silent_array.append(list(struct.unpack('<' + str(ORDER + 1) + 'f', file_data[(loop * CONCAT_MUL + loop2) * 4 * (ORDER + 1):(loop * CONCAT_MUL + loop2 + 1) * 4 * (ORDER + 1)])))\n",
        "                self.silent_array[loop * CONCAT_MUL + loop2].append(0.0)\n",
        "\n",
        "        self.get_input_voices()\n",
        "\n",
        "    def get_input_files(self, dir_path):\n",
        "        self.input_voices = glob.glob(dir_path + '/**/*.pitch', recursive=True)\n",
        "        if self.val_file == 0:\n",
        "            self.input_voices = sorted(self.input_voices)\n",
        "        else:\n",
        "            if self.train:\n",
        "                self.input_voices = sorted(self.input_voices)[:-self.val_file]\n",
        "            else:\n",
        "                self.input_voices = sorted(self.input_voices)[-self.val_file:]\n",
        "        if self.train:\n",
        "            random.shuffle(self.input_voices)\n",
        "        if self.batch_size is None:\n",
        "            self.batch_size = len(self.input_voices)\n",
        "\n",
        "    def get_input_voices(self):\n",
        "        MAX_SIZE = 512\n",
        "        CONCAT_MUL = 1\n",
        "        ORDER = 32\n",
        "\n",
        "        self.data_array = None\n",
        "\n",
        "        data_array2 = []\n",
        "        \n",
        "        max_array_size = 0\n",
        "        \n",
        "        while (self.length is None) or (len(data_array2) < self.length):\n",
        "        \n",
        "            if self.index >= len(self.input_voices):\n",
        "                self.index = 0\n",
        "                if self.train:\n",
        "                    random.shuffle(self.input_voices)\n",
        "                self.cut += 1\n",
        "                if self.cut >= 1:\n",
        "                    self.cut = 0\n",
        "                    if self.length is None:\n",
        "                        break\n",
        "            input_voice = self.input_voices[self.index]\n",
        "        \n",
        "            name, _ = os.path.splitext(input_voice)\n",
        "            \n",
        "            data_array = []\n",
        "            file_data = open(name + '.mc', 'rb').read()\n",
        "            for loop in range(len(file_data) // (4 * (ORDER + 1) * CONCAT_MUL)):\n",
        "                for loop2 in range(CONCAT_MUL):\n",
        "                    data_array.append(list(struct.unpack('<' + str(ORDER + 1) + 'f', file_data[(loop * CONCAT_MUL + loop2) * 4 * (ORDER + 1):(loop * CONCAT_MUL + loop2 + 1) * 4 * (ORDER + 1)])))\n",
        "            file_data = open(name + '.pitch', 'rb').read()\n",
        "            for loop in range(len(file_data) // (4 * CONCAT_MUL)):\n",
        "                for loop2 in range(CONCAT_MUL):\n",
        "                    pitch = struct.unpack('<f', file_data[(loop * CONCAT_MUL + loop2) * 4:(loop * CONCAT_MUL + loop2 + 1) * 4])[0]\n",
        "                    scaled_pitch = pitch / (24000.0 / 71.0) * 4.0\n",
        "                    data_array[loop * CONCAT_MUL + loop2].append(scaled_pitch)\n",
        "\n",
        "            if self.max_size is None:\n",
        "                if len(data_array) > MAX_SIZE:\n",
        "                    max_array_size = MAX_SIZE\n",
        "                elif max_array_size < len(data_array):\n",
        "                    max_array_size = len(data_array)\n",
        "                for loop in range(len(data_array) // MAX_SIZE + 1):\n",
        "                    data_array2.append(data_array[loop * MAX_SIZE:(loop + 1) * MAX_SIZE])\n",
        "            else:\n",
        "                max_array_size = self.max_size\n",
        "                for loop in range(len(data_array) // self.max_size + 1):\n",
        "                    data_array2.append(data_array[loop * self.max_size:(loop + 1) * self.max_size])\n",
        "\n",
        "            self.index += 1\n",
        "        \n",
        "        for loop in range(len(data_array2)):\n",
        "            extend_data = self.silent_array[:max_array_size - len(data_array2[loop])]\n",
        "            data_array2[loop].extend(extend_data)\n",
        "\n",
        "        self.data_array = data_array2\n",
        "        \n",
        "        self.max_size = max_array_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_array) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.length is not None:\n",
        "            self.get_input_voices()\n",
        "\n",
        "    def get_inputs(self):\n",
        "        inputs = []\n",
        "        for idx in range(len(self.data_array) // self.batch_size):\n",
        "            inputs.extend(self.data_array[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
        "        batch_inputs = np.array(inputs, dtype='float32')\n",
        "        return batch_inputs, batch_inputs\n",
        "\n",
        "\n",
        "class AngleLoss(Loss):\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = K.reshape(y_true, (-1, K.int_shape(y_true)[1], K.int_shape(y_true)[2] // 2, 2))\n",
        "        y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[1], K.int_shape(y_pred)[2] // 2, 2))\n",
        "        sum_val = K.sum(y_true * y_pred, axis=-1)\n",
        "        acos_val = tf.acos(K.clip(sum_val, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
        "        return K.mean(acos_val / math.pi, axis=-1)\n",
        "\n",
        "\n",
        "os.makedirs(model_dir_path, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "    tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)\n",
        "except KeyError:\n",
        "    #strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
        "    print('TPUが設定されていません')\n",
        "    exit(0)\n",
        "\n",
        "# 以下から引用\n",
        "# https://blog.shikoan.com/distributed-train-decorator-in-tf20/\n",
        "from enum import Enum\n",
        "\n",
        "class Reduction(Enum):\n",
        "    NONE = 0\n",
        "    SUM = 1\n",
        "    MEAN = 2\n",
        "    CONCAT = 3\n",
        "\n",
        "def distrtibuted(*reduction_flags):\n",
        "    def _decorator(fun):\n",
        "        def per_replica_reduction(z, flag):\n",
        "            if flag == Reduction.NONE:\n",
        "                return z\n",
        "            elif flag == Reduction.SUM:\n",
        "                return strategy.reduce(tf.distribute.ReduceOp.SUM, z, axis=None)\n",
        "            elif flag == Reduction.MEAN:\n",
        "                return strategy.reduce(tf.distribute.ReduceOp.MEAN, z, axis=None)\n",
        "            elif flag == Reduction.CONCAT:\n",
        "                z_list = strategy.experimental_local_results(z)\n",
        "                return tf.concat(z_list, axis=0)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "\n",
        "        @tf.function\n",
        "        def _decorated_fun(*args, **kwargs):\n",
        "            fun_result = strategy.run(fun, args=args, kwargs=kwargs)\n",
        "            if len(reduction_flags) == 0:\n",
        "                assert fun_result is None\n",
        "                return\n",
        "            elif len(reduction_flags) == 1:\n",
        "                assert type(fun_result) is not tuple and fun_result is not None\n",
        "                return per_replica_reduction(fun_result, *reduction_flags)\n",
        "            else:\n",
        "                assert type(fun_result) is tuple\n",
        "                return tuple((per_replica_reduction(fr, rf) for fr, rf in zip(fun_result, reduction_flags)))\n",
        "        return _decorated_fun\n",
        "    return _decorator\n",
        "\n",
        "with strategy.scope():\n",
        "    length = 3200 #6400\n",
        "    batch_size = 200\n",
        "    gen = VoiceGenerator('targets', 0, batch_size, length, train=True, max_size=512)\n",
        "    shape0 = gen.get_inputs()[0].shape[1]\n",
        "\n",
        "    optim_gen = Adam(0.0002, 0.5)\n",
        "    optim_dis = Adam(0.0002, 0.5)\n",
        "\n",
        "    loss_func_dis_real = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    loss_func_dis_fake = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    loss_func_dis_common = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    loss_func_gen = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    loss_func_gen_img = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    loss_func_gen_phoneme = AngleLoss(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    input_layer = Input(shape=(shape0, 128), name='gen_input')\n",
        "\n",
        "    gen_layers_pitch = LSTM(64, return_sequences=True, name='gen_pitch_lstm0')(input_layer)\n",
        "    gen_layers_pitch = LSTM(64, return_sequences=True, name='gen_pitch_lstm1')(gen_layers_pitch)\n",
        "    gen_layers_pitch = Dense(1, name='gen_pitch_dense')(gen_layers_pitch)\n",
        "\n",
        "    pitch_stopgrad_layers = Lambda(lambda x: K.stop_gradient(x), name='gen_stopgrad')(gen_layers_pitch)\n",
        "    concat_layers = Concatenate(name='gen_concat_0')([input_layer, pitch_stopgrad_layers])\n",
        "\n",
        "    gen_layers_power = LSTM(64, return_sequences=True, name='gen_power_lstm0')(input_layer)\n",
        "    gen_layers_power = LSTM(64, return_sequences=True, name='gen_power_lstm1')(gen_layers_power)\n",
        "    gen_layers_power = Dense(1, name='gen_power_dense')(gen_layers_power)\n",
        "\n",
        "    gen_layers = LSTM(128, return_sequences=True, name='gen_lstm0')(concat_layers)\n",
        "    gen_layers = LSTM(128, return_sequences=True, name='gen_lstm1')(gen_layers)\n",
        "    gen_layers = Dense(32, name='gen_dense')(gen_layers)\n",
        "\n",
        "    gen_layers = Concatenate(name='gen_concat_1')([gen_layers_power, gen_layers, gen_layers_pitch])\n",
        "\n",
        "    gen_model = Model(inputs=input_layer, outputs=gen_layers, name='gen_model')\n",
        "    gen_model.summary()\n",
        "\n",
        "    input_layer = Input(shape=(shape0, 34), name='dis_input')\n",
        "\n",
        "    dis_layers = LSTM(128, return_sequences=True, name='dis_lstm_s')(input_layer)\n",
        "    dis_layers = LSTM(64, return_sequences=True, name='dis_lstm0')(dis_layers)\n",
        "    dis_layers = Reshape((shape0 // 2, 128), name='dis_reshape0')(dis_layers)\n",
        "    dis_layers = LSTM(64, return_sequences=True, name='dis_lstm1')(dis_layers)\n",
        "    dis_layers = Reshape((shape0 // 4, 128), name='dis_reshape1')(dis_layers)\n",
        "    dis_layers = LSTM(64, return_sequences=True, name='dis_lstm2')(dis_layers)\n",
        "    dis_layers = Reshape((shape0 // 8, 128), name='dis_reshape2')(dis_layers)\n",
        "    dis_layers = Dense(1, name='dis_dense')(dis_layers)\n",
        "    #dis_layers = Activation('sigmoid', name='dis_sigmoid')(dis_layers)\n",
        "\n",
        "    dis_model = Model(inputs=input_layer, outputs=dis_layers, name='dis_model')\n",
        "    dis_model.summary()\n",
        "\n",
        "    input_layer = Input(shape=(shape0, 34), name='phoneme_input')\n",
        "\n",
        "    f_layers = LSTM(128, return_sequences=True, name='phoneme_lstm0')(input_layer)\n",
        "    f_layers = LSTM(128, return_sequences=True, name='phoneme_lstm1')(f_layers)\n",
        "    loop_layers = []\n",
        "    for loop in range(64):\n",
        "        f_layers_loop = Dense(2, name='phoneme_dense_l' + str(loop))(f_layers)\n",
        "        f_layers_loop = Lambda(lambda x: K.l2_normalize(x, axis=-1), name='phoneme_norm_l' + str(loop))(f_layers_loop)\n",
        "        loop_layers.append(f_layers_loop)\n",
        "    phoneme_layers = Concatenate(name='phoneme_concat')(loop_layers)\n",
        "\n",
        "    phoneme_model = Model(inputs=input_layer, outputs=phoneme_layers, name='phoneme_model')\n",
        "    phoneme_model.load_weights(phoneme_model_path, by_name=True)\n",
        "    phoneme_model.trainable = False\n",
        "    phoneme_model.summary()\n",
        "\n",
        "    @distrtibuted(Reduction.MEAN, Reduction.MEAN)\n",
        "    def train_on_batch(real_img, real_img_out):\n",
        "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
        "            phoneme_true = phoneme_model(real_img)\n",
        "            fake_img = gen_model(phoneme_true)\n",
        "\n",
        "        with d_tape:\n",
        "            real_out = dis_model(real_img_out)\n",
        "            fake_out = dis_model(fake_img)\n",
        "\n",
        "            d_real_loss = loss_func_dis_real(K.ones_like(real_out), real_out)\n",
        "            d_fake_loss = loss_func_dis_fake(K.zeros_like(fake_out), fake_out)\n",
        "            d_loss = d_real_loss * 0.4 + d_fake_loss * 0.8\n",
        "            d_loss = tf.reduce_sum(d_loss) * (1.0 / batch_size)\n",
        "        gradients = d_tape.gradient(d_loss, dis_model.trainable_weights)\n",
        "        optim_dis.apply_gradients(zip(gradients, dis_model.trainable_weights))\n",
        "\n",
        "        with g_tape:\n",
        "            fake_out = dis_model(fake_img)\n",
        "            #phoneme_pred = phoneme_model(fake_img)\n",
        "\n",
        "            g_dis_loss = loss_func_gen(K.ones_like(fake_out), fake_out)\n",
        "            g_dis_loss = tf.reduce_sum(g_dis_loss) * (1.0 / batch_size)\n",
        "            g_img_loss = loss_func_gen_img(real_img, fake_img)\n",
        "            g_img_loss = tf.reduce_sum(g_img_loss) * (1.0 / batch_size)\n",
        "            #g_phoneme_loss = loss_func_gen_phoneme(phoneme_true, phoneme_pred)\n",
        "            #g_phoneme_loss = tf.reduce_sum(g_phoneme_loss) * (1.0 / batch_size)\n",
        "            g_loss = g_dis_loss * 0.3 + g_img_loss * 0.5 #g_dis_loss * 0.1 + g_img_loss * 0.5 + g_phoneme_loss * 0.1\n",
        "        gradients = g_tape.gradient(g_loss, gen_model.trainable_weights)\n",
        "        optim_gen.apply_gradients(zip(gradients, gen_model.trainable_weights))\n",
        "\n",
        "        return d_loss, g_loss\n",
        "\n",
        "    start_train = True\n",
        "    epoch = start_file_epoch + 1\n",
        "    while True:\n",
        "        real_img, real_img_out = gen.get_inputs()\n",
        "        gen.on_epoch_end()\n",
        "\n",
        "        trainset = tf.data.Dataset.from_tensor_slices((real_img, real_img_out))\n",
        "        trainset = trainset.shuffle(buffer_size=length).batch(batch_size)\n",
        "        trainset = strategy.experimental_distribute_dataset(trainset)\n",
        "\n",
        "        if not load_optim_weights and start_file_dir is not None:\n",
        "            gen_model.load_weights('{}/gen_{:09d}.h5'.format(start_file_dir, start_file_epoch), by_name=True)\n",
        "            dis_model.load_weights('{}/dis_{:09d}.h5'.format(start_file_dir, start_file_epoch), by_name=True)\n",
        "\n",
        "        for loop_cnt, (X, y) in enumerate(trainset):\n",
        "            dis_loss_val, gen_loss_val = train_on_batch(X, y)\n",
        "            if start_train and start_file_dir is not None and load_optim_weights:\n",
        "                gen_model.load_weights('{}/gen_{:09d}.h5'.format(start_file_dir, start_file_epoch), by_name=True)\n",
        "                dis_model.load_weights('{}/dis_{:09d}.h5'.format(start_file_dir, start_file_epoch), by_name=True)\n",
        "                with open('{}/gen_{:09d}.pkl'.format(start_file_dir, start_file_epoch), 'rb') as f:\n",
        "                    weight_values = pickle.load(f)\n",
        "                optim_gen.set_weights(weight_values)\n",
        "                with open('{}/dis_{:09d}.pkl'.format(start_file_dir, start_file_epoch), 'rb') as f:\n",
        "                    weight_values = pickle.load(f)\n",
        "                optim_dis.set_weights(weight_values)\n",
        "                start_train = False\n",
        "\n",
        "        print('{:09d},{:.6f},{:.6f}'.format(epoch, float(gen_loss_val.numpy()), float(dis_loss_val.numpy())))\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            symbolic_weights = getattr(optim_gen, 'weights')\n",
        "            weight_values_combined = K.batch_get_value(symbolic_weights)\n",
        "            with open('{}/gen_{:09d}.pkl'.format(model_dir_path, epoch), 'wb') as f:\n",
        "                pickle.dump(weight_values_combined, f)\n",
        "\n",
        "            symbolic_weights = getattr(optim_dis, 'weights')\n",
        "            weight_values_dis = K.batch_get_value(symbolic_weights)\n",
        "            with open('{}/dis_{:09d}.pkl'.format(model_dir_path, epoch), 'wb') as f:\n",
        "                pickle.dump(weight_values_dis, f)\n",
        "\n",
        "            gen_model.save('{}/gen_{:09d}.h5'.format(model_dir_path, epoch), include_optimizer=False)\n",
        "            dis_model.save('{}/dis_{:09d}.h5'.format(model_dir_path, epoch), include_optimizer=False)\n",
        "\n",
        "            _ = open(model_dir_path + '/epoch.txt', 'w').write(str(epoch))\n",
        "\n",
        "        epoch += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}